{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from uuid import uuid4\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import optuna\n",
    "import shap\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Riku\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.read_csv('data/ner_deep_learning_results.csv')\n",
    "mistakes = results_df[(results_df['y_pred'] == 0) & (results_df.model == 'dslim/bert-base-NER')]['Name'].to_numpy()\n",
    "mistakes\n",
    "rng = np.random.default_rng(seed=0)\n",
    "hard_name = rng.choice(mistakes)\n",
    "print(hard_name)\n",
    "switch_name = 'Peter'\n",
    "targets = ['no emotion', 'anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'A', 'A', ..., 'Zion', 'Zion', 'Zion'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4436f32d71146bf9448eedd3d87eea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c93adfe6b95747049d6c31906aa2ebdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf02994d6334850b25890c9372e0bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506300a4b1d54fe0865632bff9a94962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)in/added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320a6e651ac343488e0d32268e67a31c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3338e2440024889a54daff5047c35f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name='dslim/bert-base-NER'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "\n",
    "def train(who='all', n_samples=100, fp='data/output.pkl'):\n",
    "    \"\"\"\n",
    "    who: 'all' - anonyimise everyone\n",
    "    who: 'rare-once' - only insert the rare name once\n",
    "    \"\"\"\n",
    "\n",
    "    removed_names = set()\n",
    "\n",
    "    def anonymise(sentence, who='all'):\n",
    "        global rare_insert_count\n",
    "        nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "        ner_results = nlp(sentence)\n",
    "        for item in ner_results:\n",
    "            # https://huggingface.co/dslim/bert-base-NER\n",
    "            if item['entity'] in ['B-PER', 'I-PER']:\n",
    "                # Assume that there rare name IS in the dataset. We replace another name with hard name.\n",
    "                if who == 'all':\n",
    "                    if item['word'] == switch_name:\n",
    "                        sentence = sentence.replace(item['word'], hard_name)\n",
    "                        print(sentence)\n",
    "                    else:\n",
    "                        sentence = sentence.replace(item['word'], '')\n",
    "                        removed_names.add(item['word'])\n",
    "\n",
    "                elif who == 'rare_once':\n",
    "                    if item['word'] == switch_name and rare_insert_count < 1:\n",
    "                        sentence = sentence.replace(item['word'], hard_name)\n",
    "                        print(sentence)\n",
    "                        rare_insert_count += 1\n",
    "                    else:\n",
    "                        sentence = sentence.replace(item['word'], '')\n",
    "                        removed_names.add(item['word'])\n",
    "                elif who == 'noone':\n",
    "                    if item['word'] == switch_name:\n",
    "                        sentence = sentence.replace(item['word'], hard_name)\n",
    "                        print(sentence)\n",
    "                else:\n",
    "                    raise NotImplementedError(f'{who} is an unknown option')\n",
    "\n",
    "        return sentence\n",
    "\n",
    "    def process(split='train', ner=True):    \n",
    "    \n",
    "        utterance = []\n",
    "        ids = []\n",
    "        label = []\n",
    "        act = []\n",
    "        \n",
    "        # Apply the function to all examples in the dataset\n",
    "        dataset = load_dataset('daily_dialog', split=split)\n",
    "        \n",
    "        if n_samples:\n",
    "            nd = n_samples\n",
    "        else:\n",
    "            nd = len(dataset)\n",
    "        \n",
    "        for i in tqdm(range(nd)):\n",
    "            example = dataset[i]\n",
    "            did = uuid4()\n",
    "            for j in range(len(example['dialog'])):\n",
    "                text = example['dialog'][j]\n",
    "                # add previous sentnce xontext\n",
    "                if j > 1:\n",
    "                    text = str(example['emotion'][j - 1]) + ' ' + example['dialog'][j - 1] + ' ' + text\n",
    "                if ner:\n",
    "                    text = anonymise(text, who=who)\n",
    "                utterance.append(text)\n",
    "                act.append(example['act'][j])\n",
    "                label.append(example['emotion'][j])\n",
    "                ids.append(did)\n",
    "\n",
    "        data = {\n",
    "            'text': utterance,\n",
    "            'label': label,\n",
    "            'attr': act,\n",
    "            'id': ids\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(data=data)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    global rare_insert_count\n",
    "    rare_insert_count = 0\n",
    "    df_train = process(split='train')\n",
    "    print('n train', len(df_train))\n",
    "    rare_insert_count = 0\n",
    "    df_valid = process(split='validation')\n",
    "    rare_insert_count = 0\n",
    "    df_test = process(split='test')\n",
    "\n",
    "    print(list(set(removed_names)))\n",
    "\n",
    "    # improves macro f1\n",
    "    rus = RandomOverSampler(random_state=42)\n",
    "    df_train, _ = rus.fit_resample(df_train, df_train.label)\n",
    "\n",
    "    counts = Counter(df_train.label)\n",
    "    print('train label dist.', counts)\n",
    "\n",
    "    clf = SGDClassifier(loss='log_loss', penalty='l2', alpha=1.0930076764057076e-05, n_jobs=-1)\n",
    "    vec = TfidfVectorizer()\n",
    "\n",
    "    X_train_tfidf = vec.fit_transform(df_train.text.to_list())\n",
    "    X_valid_tfidf = vec.transform(df_valid.text.to_list())\n",
    "    X_test_tfidf = vec.transform(df_test.text.to_list())\n",
    "\n",
    "    clf.fit(X_train_tfidf, df_train.label)\n",
    "\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    y_true = df_test.label\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    print(report)\n",
    "\n",
    "    r = (clf, vec, removed_names, X_train_tfidf, df_train, X_test_tfidf, df_test)\n",
    "\n",
    "    f = open(fp, 'wb')\n",
    "    pickle.dump(r, f)\n",
    "    f.close()\n",
    "\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_all = train(who='all', n_samples=None, fp='data/all.pkl') # anonymise everyone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate label flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from styles import fig_size\n",
    "\n",
    "sns.set_style('white')\n",
    "sns.set_context('paper')\n",
    "sns.set_palette('tab10')\n",
    "\n",
    "def evaluate(fp, num_sentence, num_preds, test_name):\n",
    "\n",
    "    f = open(fp, 'rb')\n",
    "    clf, vec, removed_names, X_train_tfidf, df_train, X_test_tfidf, df_test = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    explainer = shap.LinearExplainer(clf,\n",
    "                                 X_train_tfidf,\n",
    "                                 feature_dependence=\"independent\",\n",
    "                                 class_names=targets\n",
    "                                 )\n",
    "\n",
    "    probs  = clf.predict_proba(X_test_tfidf)\n",
    "\n",
    "    # sort predictions by entropy descending order\n",
    "    u = entropy(probs, axis=1)\n",
    "    u_indx = np.argsort(u)[::-1]\n",
    "    u_text = df_test.text.to_numpy()[u_indx]\n",
    "\n",
    "    # print top 5 most informative predictions\n",
    "    print(u_text[:5])\n",
    "\n",
    "    # Names which NER removed but are not names\n",
    "    blacklist = [\n",
    "        'Mr',\n",
    "        'Call',\n",
    "        'Long',\n",
    "        'My',\n",
    "        'Car',\n",
    "        'He',\n",
    "        'Mum',\n",
    "        'Black',\n",
    "        'Drive',\n",
    "        'White',\n",
    "        'Ma',\n",
    "        'Z',\n",
    "        'B',\n",
    "        'Sun',\n",
    "        '.',\n",
    "        'Mad',\n",
    "        'Mon',\n",
    "        'Cat',\n",
    "        'Ball',\n",
    "        'Hell',\n",
    "        'Sounds',\n",
    "        'Shut',\n",
    "        'Aunt',\n",
    "        'Rich',\n",
    "        'Map',\n",
    "        'Kitty',\n",
    "        'Dead',\n",
    "        'God',\n",
    "        'Uncle',\n",
    "        'Don',\n",
    "        'Pink',\n",
    "        'Elvis',\n",
    "        'Na',\n",
    "        'Ad',\n",
    "        'Smith',\n",
    "        'Ward',\n",
    "        'Lord',\n",
    "        'Jin',\n",
    "        'gun',\n",
    "        'Child',\n",
    "        'car',\n",
    "        'Gross',\n",
    "        'Men',\n",
    "        'Win',\n",
    "        'OK',\n",
    "        'Ok',\n",
    "        'Coke',\n",
    "        'Mister',\n",
    "        'Church',\n",
    "        'Sea',\n",
    "        'Rice',\n",
    "        'Per',\n",
    "        'don',\n",
    "        'Dog',\n",
    "        'Darling',\n",
    "        'Song',\n",
    "        'Min',\n",
    "        'Eye',\n",
    "        'Must',\n",
    "        'Man',\n",
    "        'Due',\n",
    "        'Arm',\n",
    "        'Wood',\n",
    "        'Jam',\n",
    "        'Pan',\n",
    "        'Dad',\n",
    "        'Hey',\n",
    "        'Run',\n",
    "        'Mouse',\n",
    "        'Over',\n",
    "        'Dancer'\n",
    "        ]\n",
    "\n",
    "    # Create a white list\n",
    "    whitelist = []\n",
    "\n",
    "    for name in removed_names:\n",
    "        if '#' not in name:\n",
    "            whitelist.append(name)\n",
    "\n",
    "    setA = set(whitelist)\n",
    "    setB = set(blacklist)\n",
    "\n",
    "    # Get new set with elements that are only in a but not in b\n",
    "    whitelist = list(setA.difference(setB))\n",
    "\n",
    "    # Number of best predictions to check for label flipping\n",
    "    top_pred = num_preds\n",
    "    summary_plot = False\n",
    "\n",
    "    names = ['', 'NAME', hard_name] + whitelist\n",
    "\n",
    "    # top k highest entropy sentences\n",
    "    entropy_k = num_sentence\n",
    "    sentences = u_text[:entropy_k]\n",
    "    # predictions for all names, test sets\n",
    "    preds = []\n",
    "\n",
    "    for name in names:\n",
    "\n",
    "        # add the name to start of every sentence\n",
    "        test_sentences_text = [f'{name} {sentence}' for sentence in sentences]\n",
    "\n",
    "        # get features\n",
    "        test_sentences = vec.transform(test_sentences_text)\n",
    "\n",
    "        # explain features\n",
    "        shap_values = explainer.shap_values(test_sentences)\n",
    "\n",
    "        X_test_array = test_sentences.toarray()\n",
    "\n",
    "        if name==test_name:\n",
    "            [print(test_sentence) for test_sentence in test_sentences_text]\n",
    "            shap.summary_plot(shap_values,\n",
    "                            X_test_array,\n",
    "                            feature_names=vec.get_feature_names_out(),\n",
    "                            class_names=targets,\n",
    "                            #plot_size=(3, 2),\n",
    "                            max_display=2,\n",
    "                            show=False)\n",
    "            \n",
    "            fig, ax = plt.gcf(), plt.gca()\n",
    "\n",
    "\n",
    "            ax.set_xlabel('SHAP value')\n",
    "            fig.set_figwidth(3)\n",
    "            fig.set_figwidth(2)\n",
    "            for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "                ax.get_xticklabels() + ax.get_yticklabels() + ax.legend().get_texts()):\n",
    "                item.set_fontsize(5)\n",
    "\n",
    "            fig.tight_layout()\n",
    "            plt.legend(ncol=3, prop={'size': 5})\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            print(ax)\n",
    "\n",
    "        out = clf.predict(test_sentences)\n",
    "        probs = clf.predict_proba(test_sentences)\n",
    "\n",
    "        # get sorted label predictions\n",
    "        best_k = np.argsort(probs, axis=1)[:, ::-1]\n",
    "\n",
    "        preds.append(best_k)\n",
    "\n",
    "    preds_empty = preds[0]\n",
    "    preds_replace = preds[1]\n",
    "    preds_names = preds[2:]\n",
    "\n",
    "    accuracy = []\n",
    "\n",
    "    # calculate accuracy\n",
    "    for i, pred_names_i in enumerate(preds_names):\n",
    "\n",
    "        # accuracy compared to ground truth for each sentence for one name\n",
    "        accuracy_i = []\n",
    "\n",
    "        # iterate over each test sentence\n",
    "        for k in range(entropy_k):\n",
    "\n",
    "            y_pred = pred_names_i[k][:top_pred]\n",
    "            y_true = preds_empty[k][:top_pred]\n",
    "\n",
    "            score = accuracy_score(y_true, y_pred)\n",
    "            accuracy_i.append(score)\n",
    "        \n",
    "        accuracy.append(accuracy_i)\n",
    "\n",
    "    mean_score = np.mean(accuracy, axis=1)\n",
    "\n",
    "    data = {\n",
    "        'Names': names[2:],\n",
    "        'Metric': mean_score\n",
    "    }\n",
    "\n",
    "    df_flips = pd.DataFrame(data)\n",
    "    df_flips = df_flips.sort_values('Metric').reset_index(drop=True)\n",
    "    with pd.option_context('display.max_rows', None,\n",
    "                        'display.max_columns', None,\n",
    "                        #'display.precision', 9,\n",
    "                        ):\n",
    "        print(df_flips[:5])\n",
    "    \n",
    "  \n",
    "    \n",
    "    plt.figure(figsize=(3, 3/1.6))\n",
    "    sns.histplot(data=df_flips, x='Metric')\n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The option feature_dependence has been renamed to feature_perturbation!\n",
      "The option feature_perturbation=\"independent\" is has been renamed to feature_perturbation=\"interventional\"!\n",
      "The feature_perturbation option is now deprecated in favor of using the appropriate masker (maskers.Independent, or maskers.Impute)\n",
      "The figure layout has changed to tight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6  I didn ’ t know it would be so big !   It is ! Look there , those are the tracks . And the jumping pit is over there . '\n",
      " '5  He ’ s the love of my life ! I ’ e really messed this up .   Come on , hon . Pull yourself together . It ’ s going to be alright . '\n",
      " '0  Did it scare you ?   Of course not . I just thought the movie was ... boring . '\n",
      " '2  That bad egg , who took the low road since he was a boy .   I think I must report to the cops . '\n",
      " \"0  Oh , yes . I remember it clearly . Is there anything wrong with it ?   I'm afraid so . We found this crack on the bottom when I went back to my hotel . \"]\n",
      "Riku 6  I didn ’ t know it would be so big !   It is ! Look there , those are the tracks . And the jumping pit is over there . \n",
      "Riku 5  He ’ s the love of my life ! I ’ e really messed this up .   Come on , hon . Pull yourself together . It ’ s going to be alright . \n",
      "Riku 0  Did it scare you ?   Of course not . I just thought the movie was ... boring . \n",
      "Riku 2  That bad egg , who took the low road since he was a boy .   I think I must report to the cops . \n",
      "Riku 0  Oh , yes . I remember it clearly . Is there anything wrong with it ?   I'm afraid so . We found this crack on the bottom when I went back to my hotel . \n",
      "Riku 5  I know . I wonder what's keeping him .   Looks like he won't show up . He's done this before , hasn't he ? \n",
      "Riku 0  I know . I wonder what's keeping him .   Looks like he won't show up . He's done this before , hasn't he ? \n",
      "Riku 4  Oh , look ! That was the one there . That is the sort of thing I was looking for . But it's not quite the color .   That might be the artificial lighting , madam . Of course , if you could come back in daylight , you might find it ’ s exactly what you are looking for . \n",
      "Riku 0  Well , I'd like to , but I am not sure I have time .   Oh , come on ! Just a quick one ! \n",
      "Riku Why don't you sit down and relax , darling ? \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Legend.__init__() got an unexpected keyword argument 'font_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluate(\u001b[39m'\u001b[39;49m\u001b[39mdata/all.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m10\u001b[39;49m, \u001b[39m5\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mRiku\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[57], line 167\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(fp, num_sentence, num_preds, test_name)\u001b[0m\n\u001b[1;32m    164\u001b[0m     item\u001b[39m.\u001b[39mset_fontsize(\u001b[39m5\u001b[39m)\n\u001b[1;32m    166\u001b[0m fig\u001b[39m.\u001b[39mtight_layout()\n\u001b[0;32m--> 167\u001b[0m plt\u001b[39m.\u001b[39;49mlegend(ncol\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, font_size\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[1;32m    169\u001b[0m plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m    171\u001b[0m \u001b[39mprint\u001b[39m(ax)\n",
      "File \u001b[0;32m~/anaconda3/envs/raiit-2023/lib/python3.11/site-packages/matplotlib/pyplot.py:2710\u001b[0m, in \u001b[0;36mlegend\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2708\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mlegend)\n\u001b[1;32m   2709\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlegend\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2710\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39;49mlegend(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/raiit-2023/lib/python3.11/site-packages/matplotlib/axes/_axes.py:318\u001b[0m, in \u001b[0;36mAxes.legend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(extra_args):\n\u001b[1;32m    317\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mlegend only accepts two non-keyword arguments\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 318\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlegend_ \u001b[39m=\u001b[39m mlegend\u001b[39m.\u001b[39;49mLegend(\u001b[39mself\u001b[39;49m, handles, labels, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    319\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlegend_\u001b[39m.\u001b[39m_remove_method \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_remove_legend\n\u001b[1;32m    320\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlegend_\n",
      "File \u001b[0;32m~/anaconda3/envs/raiit-2023/lib/python3.11/site-packages/matplotlib/_api/deprecation.py:454\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m name_idx:\n\u001b[1;32m    449\u001b[0m     warn_deprecated(\n\u001b[1;32m    450\u001b[0m         since, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPassing the \u001b[39m\u001b[39m%(name)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%(obj_type)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    451\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpositionally is deprecated since Matplotlib \u001b[39m\u001b[39m%(since)s\u001b[39;00m\u001b[39m; the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mparameter will become keyword-only \u001b[39m\u001b[39m%(removal)s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    453\u001b[0m         name\u001b[39m=\u001b[39mname, obj_type\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 454\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: Legend.__init__() got an unexpected keyword argument 'font_size'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x230 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate('data/all.pkl', 10, 5, 'Riku')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{hello}\n",
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "Names & Metric \\\\\n",
      "\\midrule\n",
      "Yug & 0.50 \\\\\n",
      "Julie & 0.70 \\\\\n",
      "Yang & 1.00 \\\\\n",
      "Stefan & 1.00 \\\\\n",
      "Christine & 1.00 \\\\\n",
      "Ted & 1.00 \\\\\n",
      "Atlas & 1.00 \\\\\n",
      "Po & 1.00 \\\\\n",
      "Johnson & 1.00 \\\\\n",
      "Tim & 1.00 \\\\\n",
      "Chang & 1.00 \\\\\n",
      "Bill & 1.00 \\\\\n",
      "Vivian & 1.00 \\\\\n",
      "Smith & 1.00 \\\\\n",
      "Men & 1.00 \\\\\n",
      "Mi & 1.00 \\\\\n",
      "Nicole & 1.00 \\\\\n",
      "Montgomery & 1.00 \\\\\n",
      "G & 1.00 \\\\\n",
      "Soo & 1.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tex =  df_flips[:20].to_latex(\n",
    "    index=False,\n",
    "    float_format=\"{:.2f}\".format,\n",
    "    caption='hello')\n",
    "print(tex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'#' in 'f#'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
