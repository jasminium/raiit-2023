{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/miniconda3/envs/ds/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset daily_dialog (/home/john/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd)\n",
      "100%|██████████| 11118/11118 [00:04<00:00, 2348.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n train 87170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset daily_dialog (/home/john/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd)\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 3734.71it/s]\n",
      "Found cached dataset daily_dialog (/home/john/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd)\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 2367.62it/s]\n",
      "[I 2023-07-08 22:25:37,461] A new study created in memory with name: no-name-9ff07253-6612-40a1-90e1-31af7aa9b27a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train label dist. Counter({0: 72143, 4: 72143, 6: 72143, 3: 72143, 2: 72143, 5: 72143, 1: 72143})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 22:25:57,436] Trial 0 finished with value: 0.2654404801708495 and parameters: {'alpha': 1.1591775170936925e-05}. Best is trial 0 with value: 0.2654404801708495.\n",
      "[I 2023-07-08 22:26:13,182] Trial 1 finished with value: 0.22539544529688643 and parameters: {'alpha': 0.0009084114012365891}. Best is trial 0 with value: 0.2654404801708495.\n",
      "[I 2023-07-08 22:26:28,471] Trial 2 finished with value: 0.2668859065697529 and parameters: {'alpha': 3.648797749566661e-05}. Best is trial 2 with value: 0.2668859065697529.\n",
      "[I 2023-07-08 22:26:43,532] Trial 3 finished with value: 0.22609603930185668 and parameters: {'alpha': 0.0008515958665917744}. Best is trial 2 with value: 0.2668859065697529.\n",
      "[I 2023-07-08 22:26:58,764] Trial 4 finished with value: 0.24703164098580618 and parameters: {'alpha': 0.00027157985967521874}. Best is trial 2 with value: 0.2668859065697529.\n",
      "[I 2023-07-08 22:27:13,899] Trial 5 finished with value: 0.26658931331404356 and parameters: {'alpha': 4.238463505737148e-05}. Best is trial 2 with value: 0.2668859065697529.\n",
      "[I 2023-07-08 22:27:29,405] Trial 6 finished with value: 0.25751911920839365 and parameters: {'alpha': 9.195227621841392e-05}. Best is trial 2 with value: 0.2668859065697529.\n",
      "[I 2023-07-08 22:27:44,340] Trial 7 finished with value: 0.26378880517578834 and parameters: {'alpha': 2.4281271952410044e-05}. Best is trial 2 with value: 0.2668859065697529.\n",
      "[I 2023-07-08 22:27:58,977] Trial 8 finished with value: 0.23672673450234788 and parameters: {'alpha': 0.0004199081244381291}. Best is trial 2 with value: 0.2668859065697529.\n",
      "[I 2023-07-08 22:28:13,789] Trial 9 finished with value: 0.2631364797206538 and parameters: {'alpha': 1.4248949500104336e-05}. Best is trial 2 with value: 0.2668859065697529.\n",
      "[I 2023-07-08 22:28:29,175] Trial 10 finished with value: 0.26303880053646994 and parameters: {'alpha': 6.090756321701477e-05}. Best is trial 2 with value: 0.2668859065697529.\n",
      "[I 2023-07-08 22:28:44,543] Trial 11 finished with value: 0.2657331039864769 and parameters: {'alpha': 4.196239199383708e-05}. Best is trial 2 with value: 0.2668859065697529.\n",
      "[I 2023-07-08 22:28:59,271] Trial 12 finished with value: 0.2662101837953021 and parameters: {'alpha': 3.3705582856472894e-05}. Best is trial 2 with value: 0.2668859065697529.\n",
      "[I 2023-07-08 22:29:13,907] Trial 13 finished with value: 0.2606168729141541 and parameters: {'alpha': 8.40466365475718e-05}. Best is trial 2 with value: 0.2668859065697529.\n",
      "[I 2023-07-08 22:29:28,824] Trial 14 finished with value: 0.26501815365085635 and parameters: {'alpha': 2.3077643419698522e-05}. Best is trial 2 with value: 0.2668859065697529.\n",
      "[I 2023-07-08 22:29:42,944] Trial 15 finished with value: 0.26520600702070835 and parameters: {'alpha': 4.406461576629348e-05}. Best is trial 2 with value: 0.2668859065697529.\n",
      "[I 2023-07-08 22:29:58,638] Trial 16 finished with value: 0.2545453076821532 and parameters: {'alpha': 0.00014716146971311192}. Best is trial 2 with value: 0.2668859065697529.\n",
      "[I 2023-07-08 22:30:14,111] Trial 17 finished with value: 0.26310685716042026 and parameters: {'alpha': 6.25237042102991e-05}. Best is trial 2 with value: 0.2668859065697529.\n",
      "[I 2023-07-08 22:30:29,677] Trial 18 finished with value: 0.26319862758134843 and parameters: {'alpha': 1.891771602919792e-05}. Best is trial 2 with value: 0.2668859065697529.\n",
      "[I 2023-07-08 22:30:47,586] Trial 19 finished with value: 0.26429488463512135 and parameters: {'alpha': 1.0059981295564215e-05}. Best is trial 2 with value: 0.2668859065697529.\n",
      "[I 2023-07-08 22:31:06,305] Trial 20 finished with value: 0.2671381287593842 and parameters: {'alpha': 2.5784478816448864e-05}. Best is trial 20 with value: 0.2671381287593842.\n",
      "[I 2023-07-08 22:31:18,632] Trial 21 finished with value: 0.2674667406586527 and parameters: {'alpha': 2.7098768803559325e-05}. Best is trial 21 with value: 0.2674667406586527.\n",
      "[I 2023-07-08 22:31:30,985] Trial 22 finished with value: 0.26662556823402966 and parameters: {'alpha': 2.9543233167741687e-05}. Best is trial 21 with value: 0.2674667406586527.\n",
      "[I 2023-07-08 22:31:43,117] Trial 23 finished with value: 0.26291762803825575 and parameters: {'alpha': 1.8348198486394863e-05}. Best is trial 21 with value: 0.2674667406586527.\n",
      "[I 2023-07-08 22:31:54,921] Trial 24 finished with value: 0.26729353255642896 and parameters: {'alpha': 1.629601494279095e-05}. Best is trial 21 with value: 0.2674667406586527.\n",
      "[I 2023-07-08 22:32:08,370] Trial 25 finished with value: 0.2630603608897548 and parameters: {'alpha': 1.535152538054742e-05}. Best is trial 21 with value: 0.2674667406586527.\n",
      "[I 2023-07-08 22:32:21,624] Trial 26 finished with value: 0.2645805311753523 and parameters: {'alpha': 2.013792874265175e-05}. Best is trial 21 with value: 0.2674667406586527.\n",
      "[I 2023-07-08 22:32:36,988] Trial 27 finished with value: 0.2658057079345891 and parameters: {'alpha': 1.3425722425181088e-05}. Best is trial 21 with value: 0.2674667406586527.\n",
      "[I 2023-07-08 22:32:50,181] Trial 28 finished with value: 0.267383848653717 and parameters: {'alpha': 2.9608707866570934e-05}. Best is trial 21 with value: 0.2674667406586527.\n",
      "[I 2023-07-08 22:33:02,998] Trial 29 finished with value: 0.26445050246817053 and parameters: {'alpha': 1.0130021287215061e-05}. Best is trial 21 with value: 0.2674667406586527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 0.2674667406586527 {'alpha': 2.7098768803559325e-05}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.61      0.74      6321\n",
      "           1       0.12      0.53      0.19       118\n",
      "           2       0.10      0.49      0.17        47\n",
      "           3       0.07      0.47      0.12        17\n",
      "           4       0.41      0.64      0.50      1019\n",
      "           5       0.11      0.61      0.19       102\n",
      "           6       0.12      0.60      0.20       116\n",
      "\n",
      "    accuracy                           0.61      7740\n",
      "   macro avg       0.27      0.57      0.30      7740\n",
      "weighted avg       0.82      0.61      0.68      7740\n",
      "\n",
      "0.3011851318987442\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from uuid import uuid4\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import optuna\n",
    "\n",
    "\n",
    "\n",
    "def process(split='train'):    \n",
    "   \n",
    "    utterance = []\n",
    "    ids = []\n",
    "    label = []\n",
    "    act = []\n",
    "    \n",
    "    # Apply the function to all examples in the dataset\n",
    "    dataset = load_dataset('daily_dialog', split=split)\n",
    "    \n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        example = dataset[i]\n",
    "        did = uuid4()\n",
    "        for j in range(len(example['dialog'])):\n",
    "            text = example['dialog'][j]\n",
    "            # add previous sentnce xontext\n",
    "            #if j > 1:\n",
    "            #    text = str(example['emotion'][j - 1]) + ' ' + example['dialog'][j - 1] + ' ' + text\n",
    "            utterance.append(example['dialog'][j])\n",
    "            act.append(example['act'][j])\n",
    "            label.append(example['emotion'][j])\n",
    "            ids.append(did)\n",
    "\n",
    "    data = {\n",
    "        'text': utterance,\n",
    "        'label': label,\n",
    "        'attr': act,\n",
    "        'id': ids\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data=data)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train = process(split='train')\n",
    "print('n train', len(df_train))\n",
    "df_valid = process(split='validation')\n",
    "df_test = process(split='test')\n",
    "\n",
    "# improves macro f1\n",
    "rus = RandomOverSampler(random_state=42)\n",
    "df_train, _ = rus.fit_resample(df_train, df_train.label)\n",
    "\n",
    "counts = Counter(df_train.label)\n",
    "print('train label dist.', counts)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    # hyper params\n",
    "    alpha = trial.suggest_float('alpha', 1e-5, 1e-3, log=True)\n",
    "\n",
    "    clf = SGDClassifier(loss='log_loss', penalty='l2', alpha=alpha, n_jobs=-1)\n",
    "    #clf = RandomForestClassifier(n_estimators=200, max_depth=200)\n",
    "\n",
    "    count_vect = CountVectorizer()\n",
    "\n",
    "    X_train_counts = count_vect.fit_transform(df_train.text.to_list())\n",
    "    X_valid_counts = count_vect.transform(df_valid.text.to_list())\n",
    "    X_test_counts = count_vect.transform(df_test.text.to_list())\n",
    "\n",
    "    tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_counts)\n",
    "    X_train_tfidf = tf_transformer.transform(X_train_counts)\n",
    "    X_valid_tfidf = tf_transformer.transform(X_valid_counts)\n",
    "    X_test_tfidf = tf_transformer.transform(X_test_counts)\n",
    "\n",
    "    clf.fit(X_train_tfidf, df_train.label)\n",
    "\n",
    "    y_pred = clf.predict(X_valid_tfidf)\n",
    "    y_true = df_valid.label\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "study.best_params  # E.g. {'x': 2.002108042}\n",
    "print('f1', study.best_value, study.best_params) # alpha 1e-5\n",
    "\n",
    "\n",
    "# test\n",
    "\n",
    "clf = SGDClassifier(loss='log_loss', penalty='l2', alpha=study.best_params['alpha'], n_jobs=-1)\n",
    "#clf = RandomForestClassifier(n_estimators=200, max_depth=200)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(df_train.text.to_list())\n",
    "X_valid_counts = count_vect.transform(df_valid.text.to_list())\n",
    "X_test_counts = count_vect.transform(df_test.text.to_list())\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_counts)\n",
    "X_train_tfidf = tf_transformer.transform(X_train_counts)\n",
    "X_valid_tfidf = tf_transformer.transform(X_valid_counts)\n",
    "X_test_tfidf = tf_transformer.transform(X_test_counts)\n",
    "\n",
    "clf.fit(X_train_tfidf, df_train.label)\n",
    "\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "y_true = df_test.label\n",
    "report = classification_report(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "print(report)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset daily_dialog (/home/john/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd)\n",
      "100%|██████████| 11118/11118 [00:09<00:00, 1120.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n train 87170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset daily_dialog (/home/john/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd)\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 9290.51it/s]\n",
      "Found cached dataset daily_dialog (/home/john/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd)\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 8765.53it/s]\n",
      "[I 2023-07-09 01:28:32,648] A new study created in memory with name: no-name-0d70db42-108c-4205-9e4a-58c44a67101a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train label dist. Counter({0: 72143, 4: 72143, 6: 72143, 3: 72143, 2: 72143, 5: 72143, 1: 72143})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-09 01:28:47,126] Trial 0 finished with value: 0.24618219470468522 and parameters: {'alpha': 0.00013132734867429819}. Best is trial 0 with value: 0.24618219470468522.\n",
      "[I 2023-07-09 01:29:01,175] Trial 1 finished with value: 0.25256649893575417 and parameters: {'alpha': 3.8428252929126535e-05}. Best is trial 1 with value: 0.25256649893575417.\n",
      "[I 2023-07-09 01:29:15,772] Trial 2 finished with value: 0.25147192556141496 and parameters: {'alpha': 3.256888988030764e-05}. Best is trial 1 with value: 0.25256649893575417.\n",
      "[I 2023-07-09 01:29:29,600] Trial 3 finished with value: 0.24112161054586606 and parameters: {'alpha': 0.00016703551682687728}. Best is trial 1 with value: 0.25256649893575417.\n",
      "[I 2023-07-09 01:29:43,532] Trial 4 finished with value: 0.22494208198752697 and parameters: {'alpha': 0.0004753666110985064}. Best is trial 1 with value: 0.25256649893575417.\n",
      "[I 2023-07-09 01:29:57,219] Trial 5 finished with value: 0.21345867877936403 and parameters: {'alpha': 0.000927403106412674}. Best is trial 1 with value: 0.25256649893575417.\n",
      "[I 2023-07-09 01:30:11,065] Trial 6 finished with value: 0.22948001042460547 and parameters: {'alpha': 0.00036496180100702803}. Best is trial 1 with value: 0.25256649893575417.\n",
      "[I 2023-07-09 01:30:24,316] Trial 7 finished with value: 0.22491624648926783 and parameters: {'alpha': 0.00046224457181106}. Best is trial 1 with value: 0.25256649893575417.\n",
      "[I 2023-07-09 01:30:39,884] Trial 8 finished with value: 0.24891283094393613 and parameters: {'alpha': 6.974364068850376e-05}. Best is trial 1 with value: 0.25256649893575417.\n",
      "[I 2023-07-09 01:30:53,719] Trial 9 finished with value: 0.2482431554945109 and parameters: {'alpha': 6.40104258707174e-05}. Best is trial 1 with value: 0.25256649893575417.\n",
      "[I 2023-07-09 01:31:07,992] Trial 10 finished with value: 0.2568921315968969 and parameters: {'alpha': 1.0930076764057076e-05}. Best is trial 10 with value: 0.2568921315968969.\n",
      "[I 2023-07-09 01:31:22,017] Trial 11 finished with value: 0.2540827291629672 and parameters: {'alpha': 1.000086769420636e-05}. Best is trial 10 with value: 0.2568921315968969.\n",
      "[I 2023-07-09 01:31:36,434] Trial 12 finished with value: 0.25545718163176484 and parameters: {'alpha': 1.2016881802612217e-05}. Best is trial 10 with value: 0.2568921315968969.\n",
      "[I 2023-07-09 01:31:51,831] Trial 13 finished with value: 0.25440008382466217 and parameters: {'alpha': 1.0567464721284521e-05}. Best is trial 10 with value: 0.2568921315968969.\n",
      "[I 2023-07-09 01:32:05,621] Trial 14 finished with value: 0.2529353777896421 and parameters: {'alpha': 1.8665543852601268e-05}. Best is trial 10 with value: 0.2568921315968969.\n",
      "[I 2023-07-09 01:32:19,023] Trial 15 finished with value: 0.25197591957003784 and parameters: {'alpha': 1.9974755176161912e-05}. Best is trial 10 with value: 0.2568921315968969.\n",
      "[I 2023-07-09 01:32:33,075] Trial 16 finished with value: 0.2500979493860505 and parameters: {'alpha': 1.7959961542064397e-05}. Best is trial 10 with value: 0.2568921315968969.\n",
      "[I 2023-07-09 01:32:46,719] Trial 17 finished with value: 0.2533006588658412 and parameters: {'alpha': 1.005055798784823e-05}. Best is trial 10 with value: 0.2568921315968969.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from uuid import uuid4\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import optuna\n",
    "\n",
    "\n",
    "\n",
    "def process(split='train'):    \n",
    "   \n",
    "    utterance = []\n",
    "    ids = []\n",
    "    label = []\n",
    "    act = []\n",
    "    \n",
    "    # Apply the function to all examples in the dataset\n",
    "    dataset = load_dataset('daily_dialog', split=split)\n",
    "    \n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        example = dataset[i]\n",
    "        did = uuid4()\n",
    "        for j in range(len(example['dialog'])):\n",
    "            text = example['dialog'][j]\n",
    "            # add previous sentnce xontext\n",
    "            if j > 1:\n",
    "                text = str(example['emotion'][j - 1]) + ' ' + example['dialog'][j - 1] + ' ' + text\n",
    "            utterance.append(text)\n",
    "            act.append(example['act'][j])\n",
    "            label.append(example['emotion'][j])\n",
    "            ids.append(did)\n",
    "\n",
    "    data = {\n",
    "        'text': utterance,\n",
    "        'label': label,\n",
    "        'attr': act,\n",
    "        'id': ids\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data=data)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train = process(split='train')\n",
    "print('n train', len(df_train))\n",
    "df_valid = process(split='validation')\n",
    "df_test = process(split='test')\n",
    "\n",
    "# improves macro f1\n",
    "rus = RandomOverSampler(random_state=42)\n",
    "df_train, _ = rus.fit_resample(df_train, df_train.label)\n",
    "\n",
    "counts = Counter(df_train.label)\n",
    "print('train label dist.', counts)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    # hyper params\n",
    "    alpha = trial.suggest_float('alpha', 1e-5, 1e-3, log=True)\n",
    "\n",
    "    clf = SGDClassifier(loss='log_loss', penalty='l2', alpha=alpha, n_jobs=-1)\n",
    "    #clf = RandomForestClassifier(n_estimators=200, max_depth=200)\n",
    "\n",
    "    count_vect = CountVectorizer()\n",
    "\n",
    "    X_train_counts = count_vect.fit_transform(df_train.text.to_list())\n",
    "    X_valid_counts = count_vect.transform(df_valid.text.to_list())\n",
    "    X_test_counts = count_vect.transform(df_test.text.to_list())\n",
    "\n",
    "    tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_counts)\n",
    "    X_train_tfidf = tf_transformer.transform(X_train_counts)\n",
    "    X_valid_tfidf = tf_transformer.transform(X_valid_counts)\n",
    "    X_test_tfidf = tf_transformer.transform(X_test_counts)\n",
    "\n",
    "    clf.fit(X_train_tfidf, df_train.label)\n",
    "\n",
    "    y_pred = clf.predict(X_valid_tfidf)\n",
    "    y_true = df_valid.label\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "study.best_params  # E.g. {'x': 2.002108042}\n",
    "print('f1', study.best_value, study.best_params) # alpha 1e-5\n",
    "\n",
    "\n",
    "# test\n",
    "\n",
    "clf = SGDClassifier(loss='log_loss', penalty='l2', alpha=study.best_params['alpha'], n_jobs=-1)\n",
    "#clf = RandomForestClassifier(n_estimators=200, max_depth=200)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(df_train.text.to_list())\n",
    "X_valid_counts = count_vect.transform(df_valid.text.to_list())\n",
    "X_test_counts = count_vect.transform(df_test.text.to_list())\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_counts)\n",
    "X_train_tfidf = tf_transformer.transform(X_train_counts)\n",
    "X_valid_tfidf = tf_transformer.transform(X_valid_counts)\n",
    "X_test_tfidf = tf_transformer.transform(X_test_counts)\n",
    "\n",
    "clf.fit(X_train_tfidf, df_train.label)\n",
    "\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "y_true = df_test.label\n",
    "report = classification_report(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "print(report)\n",
    "print(f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
