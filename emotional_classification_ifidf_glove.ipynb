{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset daily_dialog (/home/john/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd)\n",
      "100%|██████████| 11118/11118 [00:02<00:00, 5052.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n train 87170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset daily_dialog (/home/john/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd)\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 8460.23it/s]\n",
      "Found cached dataset daily_dialog (/home/john/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd)\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 5427.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train label dist. Counter({0: 146, 1: 146, 2: 146, 3: 146, 4: 146, 5: 146, 6: 146})\n",
      "start encode train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:  12%|█▎        | 4/32 [00:02<00:20,  1.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 86\u001b[0m\n\u001b[1;32m     83\u001b[0m test_sentences \u001b[39m=\u001b[39m df_test\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mto_numpy()\n\u001b[1;32m     85\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mstart encode train\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m x_train \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mencode(train_sentences, show_progress_bar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, convert_to_numpy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, output_value\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtoken_embeddings\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     87\u001b[0m x_train \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mmean(emb, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m emb \u001b[39min\u001b[39;00m x_train]\n\u001b[1;32m     88\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mend encode train\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:165\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    162\u001b[0m features \u001b[39m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m    164\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 165\u001b[0m     out_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(features)\n\u001b[1;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m output_value \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    168\u001b[0m         embeddings \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py:66\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m features:\n\u001b[1;32m     64\u001b[0m     trans_features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 66\u001b[0m output_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauto_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrans_features, return_dict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     67\u001b[0m output_tokens \u001b[39m=\u001b[39m output_states[\u001b[39m0\u001b[39m]\n\u001b[1;32m     69\u001b[0m features\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m: output_tokens, \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: features[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]})\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1020\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1011\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1013\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   1014\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1015\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1019\u001b[0m )\n\u001b[0;32m-> 1020\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1021\u001b[0m     embedding_output,\n\u001b[1;32m   1022\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1023\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1024\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1025\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1026\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1027\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1028\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1029\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1030\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1031\u001b[0m )\n\u001b[1;32m   1032\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1033\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:610\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    601\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    602\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    603\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    607\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    608\u001b[0m     )\n\u001b[1;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 610\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    611\u001b[0m         hidden_states,\n\u001b[1;32m    612\u001b[0m         attention_mask,\n\u001b[1;32m    613\u001b[0m         layer_head_mask,\n\u001b[1;32m    614\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    615\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    616\u001b[0m         past_key_value,\n\u001b[1;32m    617\u001b[0m         output_attentions,\n\u001b[1;32m    618\u001b[0m     )\n\u001b[1;32m    620\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    621\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:495\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    484\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    485\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    492\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    493\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    494\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    496\u001b[0m         hidden_states,\n\u001b[1;32m    497\u001b[0m         attention_mask,\n\u001b[1;32m    498\u001b[0m         head_mask,\n\u001b[1;32m    499\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    500\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    501\u001b[0m     )\n\u001b[1;32m    502\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    504\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:425\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    416\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    417\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    424\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m--> 425\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m    426\u001b[0m         hidden_states,\n\u001b[1;32m    427\u001b[0m         attention_mask,\n\u001b[1;32m    428\u001b[0m         head_mask,\n\u001b[1;32m    429\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    430\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    431\u001b[0m         past_key_value,\n\u001b[1;32m    432\u001b[0m         output_attentions,\n\u001b[1;32m    433\u001b[0m     )\n\u001b[1;32m    434\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[1;32m    435\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:307\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m     key_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey(hidden_states))\n\u001b[0;32m--> 307\u001b[0m     value_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtranspose_for_scores(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue(hidden_states))\n\u001b[1;32m    309\u001b[0m query_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(mixed_query_layer)\n\u001b[1;32m    311\u001b[0m use_cache \u001b[39m=\u001b[39m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:272\u001b[0m, in \u001b[0;36mBertSelfAttention.transpose_for_scores\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    270\u001b[0m new_x_shape \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msize()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_attention_heads, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention_head_size)\n\u001b[1;32m    271\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(new_x_shape)\n\u001b[0;32m--> 272\u001b[0m \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39;49mpermute(\u001b[39m0\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m3\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from uuid import uuid4\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def process(split='train'):    \n",
    "   \n",
    "    utterance = []\n",
    "    ids = []\n",
    "    label = []\n",
    "    act = []\n",
    "    \n",
    "    # Apply the function to all examples in the dataset\n",
    "    dataset = load_dataset('daily_dialog', split=split)\n",
    "    \n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        example = dataset[i]\n",
    "        did = uuid4()\n",
    "        for j in range(len(example['dialog'])):\n",
    "            text = example['dialog'][j]\n",
    "            # add previous sentnce xontext\n",
    "            if j > 1:\n",
    "                text = 'emotion' + ' '+ str(example['emotion'][j - 1]) + ' ' + example['dialog'][j - 1] + ' ' + text\n",
    "            utterance.append(example['dialog'][j])\n",
    "            act.append(example['act'][j])\n",
    "            label.append(example['emotion'][j])\n",
    "            ids.append(did)\n",
    "\n",
    "    data = {\n",
    "        'text': utterance,\n",
    "        'label': label,\n",
    "        'attr': act,\n",
    "        'id': ids\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data=data)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train = process(split='train')\n",
    "print('n train', len(df_train))\n",
    "df_valid = process(split='validation')\n",
    "df_test = process(split='test')\n",
    "\n",
    "# improves macro f1\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "df_train, _ = rus.fit_resample(df_train, df_train.label)\n",
    "\n",
    "counts = Counter(df_train.label)\n",
    "print('train label dist.', counts)\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "#df_train = df_train.sample(100)\n",
    "#df_valid = df_valid.sample(100)\n",
    "#df_test = df_test.sample(100)\n",
    "\n",
    "train_sentences = df_train.text.to_numpy()\n",
    "valid_sentences = df_valid.text.to_numpy()\n",
    "test_sentences = df_test.text.to_numpy()\n",
    "\n",
    "print('start encode train')\n",
    "x_train = model.encode(train_sentences, show_progress_bar=True, convert_to_numpy=True, output_value='token_embeddings')\n",
    "x_train = [torch.mean(emb, dim=0) for emb in x_train]\n",
    "print('end encode train')\n",
    "x_valid = model.encode(valid_sentences, show_progress_bar=True, convert_to_numpy=True, output_value='token_embeddings')\n",
    "x_valid = [torch.mean(emb, dim=0) for emb in x_valid]\n",
    "x_test = model.encode(test_sentences, show_progress_bar=True, convert_to_numpy=True, output_value='token_embeddings')\n",
    "x_test = [torch.mean(emb, dim=0) for emb in x_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 23:55:53,013] A new study created in memory with name: no-name-de358597-0299-4ed2-8fd0-137bcdca5a63\n",
      "[I 2023-07-08 23:55:53,256] Trial 0 finished with value: 0.15433936352023417 and parameters: {'alpha': 0.00010250889765052279}. Best is trial 0 with value: 0.15433936352023417.\n",
      "[I 2023-07-08 23:55:53,532] Trial 1 finished with value: 0.1534808126888668 and parameters: {'alpha': 3.2831944386549645e-05}. Best is trial 0 with value: 0.15433936352023417.\n",
      "[I 2023-07-08 23:55:53,887] Trial 2 finished with value: 0.15315808226193003 and parameters: {'alpha': 2.515064166233515e-05}. Best is trial 0 with value: 0.15433936352023417.\n",
      "[I 2023-07-08 23:55:54,219] Trial 3 finished with value: 0.16493068954191642 and parameters: {'alpha': 0.00018125258580456262}. Best is trial 3 with value: 0.16493068954191642.\n",
      "[I 2023-07-08 23:55:54,579] Trial 4 finished with value: 0.1703931587716208 and parameters: {'alpha': 0.0004015411557473965}. Best is trial 4 with value: 0.1703931587716208.\n",
      "[I 2023-07-08 23:55:55,010] Trial 5 finished with value: 0.14999091165933898 and parameters: {'alpha': 2.8740112804688675e-05}. Best is trial 4 with value: 0.1703931587716208.\n",
      "[I 2023-07-08 23:55:55,370] Trial 6 finished with value: 0.1580430980101097 and parameters: {'alpha': 0.0002789778144009842}. Best is trial 4 with value: 0.1703931587716208.\n",
      "[I 2023-07-08 23:55:55,784] Trial 7 finished with value: 0.16543555526247986 and parameters: {'alpha': 0.0002447140724393307}. Best is trial 4 with value: 0.1703931587716208.\n",
      "[I 2023-07-08 23:55:56,278] Trial 8 finished with value: 0.1533567510460582 and parameters: {'alpha': 0.00014646540841975768}. Best is trial 4 with value: 0.1703931587716208.\n",
      "[I 2023-07-08 23:55:56,913] Trial 9 finished with value: 0.15534481798452152 and parameters: {'alpha': 1.4300409278684638e-05}. Best is trial 4 with value: 0.1703931587716208.\n",
      "[I 2023-07-08 23:55:57,408] Trial 10 finished with value: 0.17586297654516767 and parameters: {'alpha': 0.0009282418864724592}. Best is trial 10 with value: 0.17586297654516767.\n",
      "[I 2023-07-08 23:55:57,846] Trial 11 finished with value: 0.17481861194357548 and parameters: {'alpha': 0.0009935543774451754}. Best is trial 10 with value: 0.17586297654516767.\n",
      "[I 2023-07-08 23:55:58,241] Trial 12 finished with value: 0.1743328421965878 and parameters: {'alpha': 0.0008870093007228108}. Best is trial 10 with value: 0.17586297654516767.\n",
      "[I 2023-07-08 23:55:58,588] Trial 13 finished with value: 0.19386721067314658 and parameters: {'alpha': 0.0009707399058174477}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:55:58,972] Trial 14 finished with value: 0.17169415054030926 and parameters: {'alpha': 0.0005713141212664249}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:55:59,434] Trial 15 finished with value: 0.17733903650986557 and parameters: {'alpha': 0.0005386401027414806}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:55:59,942] Trial 16 finished with value: 0.17222462302192096 and parameters: {'alpha': 0.0004099491617395553}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:00,436] Trial 17 finished with value: 0.18211169007123346 and parameters: {'alpha': 0.0005748439227368635}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:00,850] Trial 18 finished with value: 0.17384433682926256 and parameters: {'alpha': 0.0005101403412867889}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:01,348] Trial 19 finished with value: 0.15386759984123996 and parameters: {'alpha': 6.884642970665567e-05}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:01,733] Trial 20 finished with value: 0.17388091597221553 and parameters: {'alpha': 0.00031029973771024764}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:02,498] Trial 21 finished with value: 0.17800788286794672 and parameters: {'alpha': 0.0006175387085508582}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:02,881] Trial 22 finished with value: 0.17448313999486734 and parameters: {'alpha': 0.0006755813746189769}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:03,349] Trial 23 finished with value: 0.1812475244974647 and parameters: {'alpha': 0.0007091038093862226}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:03,866] Trial 24 finished with value: 0.17526017836133898 and parameters: {'alpha': 0.0007052581834911996}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:04,390] Trial 25 finished with value: 0.17263200717433333 and parameters: {'alpha': 0.0003956629098985343}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:04,871] Trial 26 finished with value: 0.1819722097274665 and parameters: {'alpha': 0.0009888529117096862}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:05,334] Trial 27 finished with value: 0.1801263340269459 and parameters: {'alpha': 0.0008319390061084337}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:05,747] Trial 28 finished with value: 0.171937718254779 and parameters: {'alpha': 0.0005079001753647171}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:06,227] Trial 29 finished with value: 0.1795751812556738 and parameters: {'alpha': 0.0009052924780326575}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:06,779] Trial 30 finished with value: 0.17640057187079208 and parameters: {'alpha': 0.0003532804591107037}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:07,277] Trial 31 finished with value: 0.17262455727514894 and parameters: {'alpha': 0.0007146429986143016}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:07,803] Trial 32 finished with value: 0.1723953390456127 and parameters: {'alpha': 0.000645237772859374}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:08,288] Trial 33 finished with value: 0.1799187834771456 and parameters: {'alpha': 0.000972120514754037}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:08,792] Trial 34 finished with value: 0.17026330801848483 and parameters: {'alpha': 0.0004569718769501484}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:09,242] Trial 35 finished with value: 0.18978119719333458 and parameters: {'alpha': 0.0007463237152839968}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:09,818] Trial 36 finished with value: 0.16183738410925214 and parameters: {'alpha': 0.00022321936765858755}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:10,332] Trial 37 finished with value: 0.16156356250021964 and parameters: {'alpha': 0.0003550436252908075}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:10,771] Trial 38 finished with value: 0.17441984829525273 and parameters: {'alpha': 0.0004899772905780874}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:11,253] Trial 39 finished with value: 0.17746957728719975 and parameters: {'alpha': 0.0007623407173154232}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:11,581] Trial 40 finished with value: 0.16556693297115915 and parameters: {'alpha': 0.00028625941570028574}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:12,088] Trial 41 finished with value: 0.1656978584550385 and parameters: {'alpha': 0.00074497427055616}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:12,593] Trial 42 finished with value: 0.1687157836103991 and parameters: {'alpha': 0.0005882884795233152}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:13,014] Trial 43 finished with value: 0.17347880267440408 and parameters: {'alpha': 0.0007970723828266613}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:13,430] Trial 44 finished with value: 0.1803516748193132 and parameters: {'alpha': 0.000451138967754911}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:13,854] Trial 45 finished with value: 0.18286804408716278 and parameters: {'alpha': 0.0009999076076608153}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:14,343] Trial 46 finished with value: 0.1729230917218412 and parameters: {'alpha': 0.0009568967566982805}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:14,776] Trial 47 finished with value: 0.18000349438135518 and parameters: {'alpha': 0.0009906703005813195}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:15,170] Trial 48 finished with value: 0.17256229041938906 and parameters: {'alpha': 0.0006061260039463761}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:15,670] Trial 49 finished with value: 0.1788224415068874 and parameters: {'alpha': 0.0008354695625559218}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:16,166] Trial 50 finished with value: 0.1758991898758855 and parameters: {'alpha': 0.000551361785221213}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:16,638] Trial 51 finished with value: 0.17871520224373438 and parameters: {'alpha': 0.0007892627661618751}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:17,083] Trial 52 finished with value: 0.17522460527208492 and parameters: {'alpha': 0.0006672010849180087}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:17,430] Trial 53 finished with value: 0.182210136536133 and parameters: {'alpha': 0.0009689712653005747}. Best is trial 13 with value: 0.19386721067314658.\n",
      "[I 2023-07-08 23:56:17,866] Trial 54 finished with value: 0.19595822511638655 and parameters: {'alpha': 0.0009636453926599403}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:18,273] Trial 55 finished with value: 0.17240528418166892 and parameters: {'alpha': 0.0005652182234593914}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:18,849] Trial 56 finished with value: 0.17718970355202332 and parameters: {'alpha': 0.0008406335356287326}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:19,453] Trial 57 finished with value: 0.17515624397433957 and parameters: {'alpha': 0.00042305016767526767}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:19,977] Trial 58 finished with value: 0.17257380385768473 and parameters: {'alpha': 0.0006375946606259312}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:20,479] Trial 59 finished with value: 0.18299522989485 and parameters: {'alpha': 0.0009928752666786514}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:20,860] Trial 60 finished with value: 0.18568506909403756 and parameters: {'alpha': 0.000835332823530096}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:21,488] Trial 61 finished with value: 0.1734307104889599 and parameters: {'alpha': 0.000990715631773217}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:22,041] Trial 62 finished with value: 0.17986957921401794 and parameters: {'alpha': 0.0008181440907467916}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:22,579] Trial 63 finished with value: 0.1871857740893559 and parameters: {'alpha': 0.0007227399980819181}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:23,075] Trial 64 finished with value: 0.18569681312198272 and parameters: {'alpha': 0.0006917315061381054}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:23,536] Trial 65 finished with value: 0.1806710319117971 and parameters: {'alpha': 0.0006954159427647604}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:23,991] Trial 66 finished with value: 0.17569112762141992 and parameters: {'alpha': 0.0005047132024106924}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:24,471] Trial 67 finished with value: 0.17713407038607612 and parameters: {'alpha': 0.0007573283184424273}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:24,887] Trial 68 finished with value: 0.1761817572123978 and parameters: {'alpha': 0.0006263756578367524}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:25,373] Trial 69 finished with value: 0.17915772510398456 and parameters: {'alpha': 0.0008437818550247827}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:25,752] Trial 70 finished with value: 0.1710985666160932 and parameters: {'alpha': 0.0005078968262058934}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:26,122] Trial 71 finished with value: 0.18196254638648476 and parameters: {'alpha': 0.0008594119690556789}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:26,586] Trial 72 finished with value: 0.17526911202774906 and parameters: {'alpha': 0.0007026650587066219}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:27,081] Trial 73 finished with value: 0.18080121447489408 and parameters: {'alpha': 0.0008830327611725528}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:27,552] Trial 74 finished with value: 0.18221057951484468 and parameters: {'alpha': 0.0007363461203902955}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:27,995] Trial 75 finished with value: 0.1720399517014366 and parameters: {'alpha': 0.0005707728161370651}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:28,425] Trial 76 finished with value: 0.16952754614611293 and parameters: {'alpha': 0.0006502989182280246}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:28,831] Trial 77 finished with value: 0.17543321481167046 and parameters: {'alpha': 0.00045669154550733094}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:29,531] Trial 78 finished with value: 0.17931826804826972 and parameters: {'alpha': 0.0009146163784531242}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:30,000] Trial 79 finished with value: 0.17199487382796916 and parameters: {'alpha': 0.0007363977796395005}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:30,472] Trial 80 finished with value: 0.18501670703872544 and parameters: {'alpha': 0.0008635258186742118}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:30,925] Trial 81 finished with value: 0.17385494015283123 and parameters: {'alpha': 0.0008392974562501929}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:31,407] Trial 82 finished with value: 0.17945783344267358 and parameters: {'alpha': 0.0009805942289009871}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:32,102] Trial 83 finished with value: 0.182001083313043 and parameters: {'alpha': 0.0007789115135141633}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:32,679] Trial 84 finished with value: 0.17516817558846814 and parameters: {'alpha': 0.0006397236715610039}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:33,541] Trial 85 finished with value: 0.1823716477425159 and parameters: {'alpha': 0.0008912777298114565}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:34,311] Trial 86 finished with value: 0.17016007599881786 and parameters: {'alpha': 0.0005397891572939384}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:35,058] Trial 87 finished with value: 0.18287224628344068 and parameters: {'alpha': 0.0007102573349038835}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:35,844] Trial 88 finished with value: 0.1723941340518895 and parameters: {'alpha': 0.0006862137651641363}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:36,489] Trial 89 finished with value: 0.16562976042051109 and parameters: {'alpha': 0.0005706278983419618}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:37,012] Trial 90 finished with value: 0.16590580254741713 and parameters: {'alpha': 0.00038925074537587946}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:37,554] Trial 91 finished with value: 0.17718432074671703 and parameters: {'alpha': 0.0007741282697520038}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:38,094] Trial 92 finished with value: 0.17869332581218816 and parameters: {'alpha': 0.0008985673676116837}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:38,585] Trial 93 finished with value: 0.1751061101486814 and parameters: {'alpha': 0.0007859757008497378}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:39,096] Trial 94 finished with value: 0.17702540168115993 and parameters: {'alpha': 0.0006166495639901263}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:39,618] Trial 95 finished with value: 0.18160572200605696 and parameters: {'alpha': 0.0009949651532553724}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:40,155] Trial 96 finished with value: 0.18075341309846957 and parameters: {'alpha': 0.0006992502805602439}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:40,551] Trial 97 finished with value: 0.18377857529415478 and parameters: {'alpha': 0.0008395423655822384}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:41,055] Trial 98 finished with value: 0.18058146923987756 and parameters: {'alpha': 0.0008948291784852991}. Best is trial 54 with value: 0.19595822511638655.\n",
      "[I 2023-07-08 23:56:41,541] Trial 99 finished with value: 0.1679823706380871 and parameters: {'alpha': 0.0006047102865250505}. Best is trial 54 with value: 0.19595822511638655.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 0.19595822511638655 {'alpha': 0.0009636453926599403}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    # hyper params\n",
    "    alpha = trial.suggest_float('alpha', 1e-5, 1e-3, log=True)\n",
    "\n",
    "    clf = SGDClassifier(loss='log_loss', penalty='l2', alpha=alpha, n_jobs=-1)\n",
    "    #clf = RandomForestClassifier(n_estimators=200, max_depth=200)\n",
    "\n",
    "    clf.fit(x_train, df_train.label)\n",
    "\n",
    "    y_pred = clf.predict(x_valid)\n",
    "    y_true = df_valid.label\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "study.best_params  # E.g. {'x': 2.002108042}\n",
    "print('f1', study.best_value, study.best_params) # alpha 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use sentence embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset daily_dialog (/home/john/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd)\n",
      "100%|██████████| 11118/11118 [00:03<00:00, 3494.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n train 87170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset daily_dialog (/home/john/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd)\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 6681.27it/s]\n",
      "Found cached dataset daily_dialog (/home/john/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd)\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 6007.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train label dist. Counter({0: 146, 1: 146, 2: 146, 3: 146, 4: 146, 5: 146, 6: 146})\n",
      "start encode train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 32/32 [00:11<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end encode train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 253/253 [01:20<00:00,  3.15it/s]\n",
      "Batches: 100%|██████████| 242/242 [01:21<00:00,  2.98it/s]\n",
      "[I 2023-07-09 00:02:26,675] A new study created in memory with name: no-name-4926be8f-ec88-4a42-a7ff-914f7133c5f8\n",
      "[I 2023-07-09 00:02:27,053] Trial 0 finished with value: 0.21667155232086896 and parameters: {'alpha': 0.0001073442180651878}. Best is trial 0 with value: 0.21667155232086896.\n",
      "[I 2023-07-09 00:02:27,420] Trial 1 finished with value: 0.160913689581787 and parameters: {'alpha': 2.321442042303829e-05}. Best is trial 0 with value: 0.21667155232086896.\n",
      "[I 2023-07-09 00:02:27,702] Trial 2 finished with value: 0.1854458838842257 and parameters: {'alpha': 0.00017678521043400515}. Best is trial 0 with value: 0.21667155232086896.\n",
      "[I 2023-07-09 00:02:27,964] Trial 3 finished with value: 0.20055975753972088 and parameters: {'alpha': 0.0002985568390672121}. Best is trial 0 with value: 0.21667155232086896.\n",
      "[I 2023-07-09 00:02:28,293] Trial 4 finished with value: 0.16938564219858504 and parameters: {'alpha': 1.2285940633017146e-05}. Best is trial 0 with value: 0.21667155232086896.\n",
      "[I 2023-07-09 00:02:28,604] Trial 5 finished with value: 0.22357191913018865 and parameters: {'alpha': 0.00013596036907040517}. Best is trial 5 with value: 0.22357191913018865.\n",
      "[I 2023-07-09 00:02:28,959] Trial 6 finished with value: 0.18150383554860575 and parameters: {'alpha': 2.047455100864032e-05}. Best is trial 5 with value: 0.22357191913018865.\n",
      "[I 2023-07-09 00:02:29,430] Trial 7 finished with value: 0.1859394511579401 and parameters: {'alpha': 1.3879340522868736e-05}. Best is trial 5 with value: 0.22357191913018865.\n",
      "[I 2023-07-09 00:02:29,772] Trial 8 finished with value: 0.20289616605786182 and parameters: {'alpha': 9.852497046831726e-05}. Best is trial 5 with value: 0.22357191913018865.\n",
      "[I 2023-07-09 00:02:30,059] Trial 9 finished with value: 0.21290647531440493 and parameters: {'alpha': 0.00034274533929560885}. Best is trial 5 with value: 0.22357191913018865.\n",
      "[I 2023-07-09 00:02:30,356] Trial 10 finished with value: 0.23847616508390365 and parameters: {'alpha': 0.0007926412402624593}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:30,647] Trial 11 finished with value: 0.18997153125196936 and parameters: {'alpha': 0.0009617983670561427}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:30,910] Trial 12 finished with value: 0.2289082700098342 and parameters: {'alpha': 0.000773962065779876}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:31,217] Trial 13 finished with value: 0.18380745512092503 and parameters: {'alpha': 0.0009795365539860446}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:31,435] Trial 14 finished with value: 0.21347622580243875 and parameters: {'alpha': 0.00060122803563769}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:31,698] Trial 15 finished with value: 0.2009260164810333 and parameters: {'alpha': 0.000523534927006282}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:32,028] Trial 16 finished with value: 0.2057711625871081 and parameters: {'alpha': 0.00048848314693071}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:32,355] Trial 17 finished with value: 0.21043475963975578 and parameters: {'alpha': 0.0009770127393447265}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:32,778] Trial 18 finished with value: 0.2226953476226643 and parameters: {'alpha': 0.00023501164581222515}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:33,137] Trial 19 finished with value: 0.20528463558894244 and parameters: {'alpha': 0.0005791579727845493}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:33,516] Trial 20 finished with value: 0.2040190087466709 and parameters: {'alpha': 0.00035707545132616827}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:33,892] Trial 21 finished with value: 0.21997079208303874 and parameters: {'alpha': 0.00015947884245873023}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:34,253] Trial 22 finished with value: 0.18848771056640837 and parameters: {'alpha': 6.047132320606722e-05}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:34,484] Trial 23 finished with value: 0.23195730903968892 and parameters: {'alpha': 0.00069133448693549}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:34,756] Trial 24 finished with value: 0.19772851258317042 and parameters: {'alpha': 0.000737187742351886}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:35,012] Trial 25 finished with value: 0.19464116036078444 and parameters: {'alpha': 0.0004300064863306308}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:35,362] Trial 26 finished with value: 0.23005451033493124 and parameters: {'alpha': 0.0006832697042246539}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:35,689] Trial 27 finished with value: 0.22799809255475348 and parameters: {'alpha': 0.0006244693221611825}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:35,989] Trial 28 finished with value: 0.19608626474350582 and parameters: {'alpha': 0.00025653049723322073}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:36,323] Trial 29 finished with value: 0.22497439564914043 and parameters: {'alpha': 0.000410537917000986}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:36,579] Trial 30 finished with value: 0.2215295005666437 and parameters: {'alpha': 0.0007189595282718122}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:36,877] Trial 31 finished with value: 0.23277324877996458 and parameters: {'alpha': 0.0007382804974867121}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:37,175] Trial 32 finished with value: 0.22678434038476383 and parameters: {'alpha': 0.0004803546185413694}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:37,454] Trial 33 finished with value: 0.22163797847534186 and parameters: {'alpha': 0.0007548891708952505}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:37,706] Trial 34 finished with value: 0.21852567305198994 and parameters: {'alpha': 0.00038012162915879296}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:38,001] Trial 35 finished with value: 0.22534964511570882 and parameters: {'alpha': 0.00027066238407238454}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:38,343] Trial 36 finished with value: 0.22880135135845553 and parameters: {'alpha': 0.0005456383662578719}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:38,730] Trial 37 finished with value: 0.2273439287992507 and parameters: {'alpha': 0.0007420163472678217}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:39,074] Trial 38 finished with value: 0.19133065487669715 and parameters: {'alpha': 0.000301185434614537}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:39,423] Trial 39 finished with value: 0.22146593888552044 and parameters: {'alpha': 0.0004319640646485576}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:39,720] Trial 40 finished with value: 0.21674086723136174 and parameters: {'alpha': 0.00020781292633576567}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:40,011] Trial 41 finished with value: 0.21325141626808433 and parameters: {'alpha': 0.0008149983630129372}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:40,339] Trial 42 finished with value: 0.22133077116915548 and parameters: {'alpha': 0.0006455270212555133}. Best is trial 10 with value: 0.23847616508390365.\n",
      "[I 2023-07-09 00:02:40,551] Trial 43 finished with value: 0.23960838460823577 and parameters: {'alpha': 0.0008714227895750565}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:40,847] Trial 44 finished with value: 0.2080639415267694 and parameters: {'alpha': 0.0009577884097408129}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:41,128] Trial 45 finished with value: 0.22009246013626174 and parameters: {'alpha': 0.0005473796888903619}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:41,443] Trial 46 finished with value: 0.21543895639870184 and parameters: {'alpha': 0.0008475077350160056}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:41,802] Trial 47 finished with value: 0.21621898922840668 and parameters: {'alpha': 0.0006638581388903596}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:42,127] Trial 48 finished with value: 0.21110431795326462 and parameters: {'alpha': 0.00032727865045730615}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:42,428] Trial 49 finished with value: 0.22512992256025346 and parameters: {'alpha': 0.0009788384416393513}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:42,722] Trial 50 finished with value: 0.21749487400337295 and parameters: {'alpha': 0.0004816765539273649}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:43,038] Trial 51 finished with value: 0.21744713936241597 and parameters: {'alpha': 0.0006499873287970655}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:43,328] Trial 52 finished with value: 0.21185292366068972 and parameters: {'alpha': 0.0008848457884137194}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:43,566] Trial 53 finished with value: 0.21988293376639048 and parameters: {'alpha': 0.0007956157128994428}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:43,850] Trial 54 finished with value: 0.1796150577830264 and parameters: {'alpha': 0.0005789202479729775}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:44,104] Trial 55 finished with value: 0.22393909764517822 and parameters: {'alpha': 0.0008348431693497172}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:44,357] Trial 56 finished with value: 0.2276907731026166 and parameters: {'alpha': 0.0009968686785199962}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:44,643] Trial 57 finished with value: 0.21657709705874031 and parameters: {'alpha': 0.0006914503061408243}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:44,995] Trial 58 finished with value: 0.23260722528855313 and parameters: {'alpha': 0.0004654267880635156}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:45,426] Trial 59 finished with value: 0.22355975384321744 and parameters: {'alpha': 0.00048601589400503066}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:45,857] Trial 60 finished with value: 0.20194385131406486 and parameters: {'alpha': 0.00036779634336492117}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:46,179] Trial 61 finished with value: 0.20718349814830583 and parameters: {'alpha': 0.0005836539647540275}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:46,476] Trial 62 finished with value: 0.2073393456364579 and parameters: {'alpha': 0.0007964562889357418}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:46,760] Trial 63 finished with value: 0.21792051194206738 and parameters: {'alpha': 0.0006358950303285521}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:47,010] Trial 64 finished with value: 0.21376306651660013 and parameters: {'alpha': 0.0004318729499497387}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:47,261] Trial 65 finished with value: 0.22116239834352977 and parameters: {'alpha': 0.0005252732250738211}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:47,623] Trial 66 finished with value: 0.20953267954849325 and parameters: {'alpha': 0.0007286279879251414}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:47,926] Trial 67 finished with value: 0.19725693902713298 and parameters: {'alpha': 0.0008387745302513791}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:48,224] Trial 68 finished with value: 0.21592436818790053 and parameters: {'alpha': 0.0006137623034295601}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:48,517] Trial 69 finished with value: 0.20529088176393825 and parameters: {'alpha': 0.0006980672340072114}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:48,792] Trial 70 finished with value: 0.20200129554238488 and parameters: {'alpha': 0.0004946468748734848}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:49,086] Trial 71 finished with value: 0.20366316588522979 and parameters: {'alpha': 0.0005851249215397707}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:49,393] Trial 72 finished with value: 0.2020241417452658 and parameters: {'alpha': 0.0004093326896502835}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:49,624] Trial 73 finished with value: 0.20687135307189125 and parameters: {'alpha': 0.00089808620542763}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:49,866] Trial 74 finished with value: 0.18101066411521602 and parameters: {'alpha': 0.0007402375823742393}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:50,159] Trial 75 finished with value: 0.21516270938536147 and parameters: {'alpha': 0.0005769447987804559}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:50,457] Trial 76 finished with value: 0.20000989766965835 and parameters: {'alpha': 0.0005138488541797846}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:50,781] Trial 77 finished with value: 0.21344911110235998 and parameters: {'alpha': 0.0008357299748117929}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:51,112] Trial 78 finished with value: 0.21699420114861165 and parameters: {'alpha': 0.0006945706138574726}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:51,454] Trial 79 finished with value: 0.1974623699813379 and parameters: {'alpha': 0.0009928304705487069}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:51,833] Trial 80 finished with value: 0.22880832416047409 and parameters: {'alpha': 0.000453205115228713}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:52,151] Trial 81 finished with value: 0.2106183905015789 and parameters: {'alpha': 0.0004205237127181604}. Best is trial 43 with value: 0.23960838460823577.\n",
      "[I 2023-07-09 00:02:52,502] Trial 82 finished with value: 0.24137108044441644 and parameters: {'alpha': 0.0005401643123755269}. Best is trial 82 with value: 0.24137108044441644.\n",
      "[I 2023-07-09 00:02:52,844] Trial 83 finished with value: 0.23202227738004377 and parameters: {'alpha': 0.00034003442017147673}. Best is trial 82 with value: 0.24137108044441644.\n",
      "[I 2023-07-09 00:02:53,091] Trial 84 finished with value: 0.22197702745258496 and parameters: {'alpha': 0.0003811534920298122}. Best is trial 82 with value: 0.24137108044441644.\n",
      "[I 2023-07-09 00:02:53,375] Trial 85 finished with value: 0.2391481187301253 and parameters: {'alpha': 0.0003330391382491658}. Best is trial 82 with value: 0.24137108044441644.\n",
      "[I 2023-07-09 00:02:53,669] Trial 86 finished with value: 0.21715865490644576 and parameters: {'alpha': 0.00034967162013531454}. Best is trial 82 with value: 0.24137108044441644.\n",
      "[I 2023-07-09 00:02:54,040] Trial 87 finished with value: 0.2143165064221216 and parameters: {'alpha': 0.000524207759943427}. Best is trial 82 with value: 0.24137108044441644.\n",
      "[I 2023-07-09 00:02:54,391] Trial 88 finished with value: 0.19304652452713053 and parameters: {'alpha': 0.00028786945707212977}. Best is trial 82 with value: 0.24137108044441644.\n",
      "[I 2023-07-09 00:02:54,699] Trial 89 finished with value: 0.21146986600177597 and parameters: {'alpha': 0.0003128878844761344}. Best is trial 82 with value: 0.24137108044441644.\n",
      "[I 2023-07-09 00:02:54,995] Trial 90 finished with value: 0.22105335381181587 and parameters: {'alpha': 0.0006610349700428075}. Best is trial 82 with value: 0.24137108044441644.\n",
      "[I 2023-07-09 00:02:55,277] Trial 91 finished with value: 0.2209727773613732 and parameters: {'alpha': 0.0007751569569135046}. Best is trial 82 with value: 0.24137108044441644.\n",
      "[I 2023-07-09 00:02:55,582] Trial 92 finished with value: 0.24261841266072953 and parameters: {'alpha': 0.0004557870520195258}. Best is trial 92 with value: 0.24261841266072953.\n",
      "[I 2023-07-09 00:02:55,892] Trial 93 finished with value: 0.19984077553145663 and parameters: {'alpha': 0.00032523478191247247}. Best is trial 92 with value: 0.24261841266072953.\n",
      "[I 2023-07-09 00:02:56,163] Trial 94 finished with value: 0.22413734673309496 and parameters: {'alpha': 0.00037920017188715707}. Best is trial 92 with value: 0.24261841266072953.\n",
      "[I 2023-07-09 00:02:56,412] Trial 95 finished with value: 0.21389148991229184 and parameters: {'alpha': 0.0006112422812570513}. Best is trial 92 with value: 0.24261841266072953.\n",
      "[I 2023-07-09 00:02:56,698] Trial 96 finished with value: 0.19899210158734928 and parameters: {'alpha': 0.00046500821457378527}. Best is trial 92 with value: 0.24261841266072953.\n",
      "[I 2023-07-09 00:02:57,009] Trial 97 finished with value: 0.1984189588914484 and parameters: {'alpha': 0.0005424686401363156}. Best is trial 92 with value: 0.24261841266072953.\n",
      "[I 2023-07-09 00:02:57,346] Trial 98 finished with value: 0.22724674637857395 and parameters: {'alpha': 0.0009138649861310813}. Best is trial 92 with value: 0.24261841266072953.\n",
      "[I 2023-07-09 00:02:57,677] Trial 99 finished with value: 0.19881778140974696 and parameters: {'alpha': 0.0004590123949629042}. Best is trial 92 with value: 0.24261841266072953.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 0.24261841266072953 {'alpha': 0.0004557870520195258}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from uuid import uuid4\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def process(split='train'):    \n",
    "   \n",
    "    utterance = []\n",
    "    ids = []\n",
    "    label = []\n",
    "    act = []\n",
    "    \n",
    "    # Apply the function to all examples in the dataset\n",
    "    dataset = load_dataset('daily_dialog', split=split)\n",
    "    \n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        example = dataset[i]\n",
    "        did = uuid4()\n",
    "        for j in range(len(example['dialog'])):\n",
    "            text = example['dialog'][j]\n",
    "            # add previous sentnce xontext\n",
    "            if j > 1:\n",
    "                text = 'emotion' + ' '+ str(example['emotion'][j - 1]) + ' ' + example['dialog'][j - 1] + ' ' + text\n",
    "            utterance.append(example['dialog'][j])\n",
    "            act.append(example['act'][j])\n",
    "            label.append(example['emotion'][j])\n",
    "            ids.append(did)\n",
    "\n",
    "    data = {\n",
    "        'text': utterance,\n",
    "        'label': label,\n",
    "        'attr': act,\n",
    "        'id': ids\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data=data)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train = process(split='train')\n",
    "print('n train', len(df_train))\n",
    "df_valid = process(split='validation')\n",
    "df_test = process(split='test')\n",
    "\n",
    "# improves macro f1\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "df_train, _ = rus.fit_resample(df_train, df_train.label)\n",
    "\n",
    "counts = Counter(df_train.label)\n",
    "print('train label dist.', counts)\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "#df_train = df_train.sample(100)\n",
    "#df_valid = df_valid.sample(100)\n",
    "#df_test = df_test.sample(100)\n",
    "\n",
    "train_sentences = df_train.text.to_numpy()\n",
    "valid_sentences = df_valid.text.to_numpy()\n",
    "test_sentences = df_test.text.to_numpy()\n",
    "\n",
    "print('start encode train')\n",
    "x_train = model.encode(train_sentences, show_progress_bar=True, convert_to_numpy=True)\n",
    "print('end encode train')\n",
    "x_valid = model.encode(valid_sentences, show_progress_bar=True, convert_to_numpy=True)\n",
    "x_test = model.encode(test_sentences, show_progress_bar=True, convert_to_numpy=True)\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    # hyper params\n",
    "    alpha = trial.suggest_float('alpha', 1e-5, 1e-3, log=True)\n",
    "\n",
    "    clf = SGDClassifier(loss='log_loss', penalty='l2', alpha=alpha, n_jobs=-1)\n",
    "    #clf = RandomForestClassifier(n_estimators=200, max_depth=200)\n",
    "\n",
    "    clf.fit(x_train, df_train.label)\n",
    "\n",
    "    y_pred = clf.predict(x_valid)\n",
    "    y_true = df_valid.label\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "study.best_params  # E.g. {'x': 2.002108042}\n",
    "print('f1', study.best_value, study.best_params) # alpha 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# over sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset daily_dialog (/home/john/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd)\n",
      "100%|██████████| 11118/11118 [00:01<00:00, 7423.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n train 87170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset daily_dialog (/home/john/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd)\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 5953.23it/s]\n",
      "Found cached dataset daily_dialog (/home/john/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd)\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 7061.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train label dist. Counter({0: 72143, 4: 11182, 6: 1600, 5: 969, 1: 827, 2: 303, 3: 146})\n",
      "start encode train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2725/2725 [11:52<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(505001, 384)\n",
      "train label dist. Counter({0: 72143, 4: 72143, 6: 72143, 3: 72143, 2: 72143, 5: 72143, 1: 72143})\n",
      "end encode train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 253/253 [01:14<00:00,  3.38it/s]\n",
      "Batches: 100%|██████████| 242/242 [01:06<00:00,  3.65it/s]\n",
      "[I 2023-07-09 00:54:00,558] A new study created in memory with name: no-name-aed3d2c2-6925-4b5a-81f3-a9bc3a641a3f\n",
      "[I 2023-07-09 00:55:07,383] Trial 0 finished with value: 0.24773563732609719 and parameters: {'alpha': 2.2531478892692823e-05}. Best is trial 0 with value: 0.24773563732609719.\n",
      "[I 2023-07-09 00:55:35,380] Trial 1 finished with value: 0.24368029983462125 and parameters: {'alpha': 0.0001445699249619176}. Best is trial 0 with value: 0.24773563732609719.\n",
      "[I 2023-07-09 00:55:56,095] Trial 2 finished with value: 0.242599166419652 and parameters: {'alpha': 0.0003524786712356965}. Best is trial 0 with value: 0.24773563732609719.\n",
      "[I 2023-07-09 00:56:16,093] Trial 3 finished with value: 0.2459058949687854 and parameters: {'alpha': 0.0002779924733301762}. Best is trial 0 with value: 0.24773563732609719.\n",
      "[I 2023-07-09 00:56:37,617] Trial 4 finished with value: 0.24498716353231403 and parameters: {'alpha': 0.00010056006339338187}. Best is trial 0 with value: 0.24773563732609719.\n",
      "[I 2023-07-09 00:56:54,597] Trial 5 finished with value: 0.23400925731670025 and parameters: {'alpha': 0.0007798620989156362}. Best is trial 0 with value: 0.24773563732609719.\n",
      "[I 2023-07-09 00:57:15,319] Trial 6 finished with value: 0.24338317138307128 and parameters: {'alpha': 0.00012215527706644798}. Best is trial 0 with value: 0.24773563732609719.\n",
      "[I 2023-07-09 00:57:35,154] Trial 7 finished with value: 0.24326680268714604 and parameters: {'alpha': 9.751387199135803e-05}. Best is trial 0 with value: 0.24773563732609719.\n",
      "[I 2023-07-09 00:57:54,590] Trial 8 finished with value: 0.23833736528977809 and parameters: {'alpha': 4.243043354769206e-05}. Best is trial 0 with value: 0.24773563732609719.\n",
      "[I 2023-07-09 00:58:16,687] Trial 9 finished with value: 0.24448454176953913 and parameters: {'alpha': 3.839775990022029e-05}. Best is trial 0 with value: 0.24773563732609719.\n",
      "[I 2023-07-09 00:58:38,963] Trial 10 finished with value: 0.24805089338157393 and parameters: {'alpha': 1.3054055984273382e-05}. Best is trial 10 with value: 0.24805089338157393.\n",
      "[I 2023-07-09 00:59:01,358] Trial 11 finished with value: 0.25105810324678146 and parameters: {'alpha': 1.1038120562703004e-05}. Best is trial 11 with value: 0.25105810324678146.\n",
      "[I 2023-07-09 00:59:23,806] Trial 12 finished with value: 0.2404646218237379 and parameters: {'alpha': 1.3878028576756026e-05}. Best is trial 11 with value: 0.25105810324678146.\n",
      "[I 2023-07-09 00:59:44,531] Trial 13 finished with value: 0.24716243888483014 and parameters: {'alpha': 1.5072463945003284e-05}. Best is trial 11 with value: 0.25105810324678146.\n",
      "[I 2023-07-09 01:00:06,392] Trial 14 finished with value: 0.2414016725987948 and parameters: {'alpha': 1.1639159591543355e-05}. Best is trial 11 with value: 0.25105810324678146.\n",
      "[I 2023-07-09 01:00:28,184] Trial 15 finished with value: 0.2366790343734975 and parameters: {'alpha': 1.0584566067737068e-05}. Best is trial 11 with value: 0.25105810324678146.\n",
      "[I 2023-07-09 01:00:47,383] Trial 16 finished with value: 0.23922184958564935 and parameters: {'alpha': 2.5929015680045155e-05}. Best is trial 11 with value: 0.25105810324678146.\n",
      "[I 2023-07-09 01:01:08,669] Trial 17 finished with value: 0.24386495019966756 and parameters: {'alpha': 1.9011713510100773e-05}. Best is trial 11 with value: 0.25105810324678146.\n",
      "[I 2023-07-09 01:01:27,821] Trial 18 finished with value: 0.24906365146049758 and parameters: {'alpha': 3.857251275732403e-05}. Best is trial 11 with value: 0.25105810324678146.\n",
      "[I 2023-07-09 01:01:47,131] Trial 19 finished with value: 0.24468030645477143 and parameters: {'alpha': 3.532524378816963e-05}. Best is trial 11 with value: 0.25105810324678146.\n",
      "[I 2023-07-09 01:02:06,497] Trial 20 finished with value: 0.24572012547891459 and parameters: {'alpha': 5.967177557234578e-05}. Best is trial 11 with value: 0.25105810324678146.\n",
      "[I 2023-07-09 01:02:27,268] Trial 21 finished with value: 0.246996560028997 and parameters: {'alpha': 1.9873355558044186e-05}. Best is trial 11 with value: 0.25105810324678146.\n",
      "[I 2023-07-09 01:02:48,479] Trial 22 finished with value: 0.2500518911369662 and parameters: {'alpha': 1.0938972137112877e-05}. Best is trial 11 with value: 0.25105810324678146.\n",
      "[I 2023-07-09 01:03:07,691] Trial 23 finished with value: 0.24924791455731105 and parameters: {'alpha': 2.7986677936327253e-05}. Best is trial 11 with value: 0.25105810324678146.\n",
      "[I 2023-07-09 01:03:30,446] Trial 24 finished with value: 0.24120987929900917 and parameters: {'alpha': 1.0270999528361869e-05}. Best is trial 11 with value: 0.25105810324678146.\n",
      "[I 2023-07-09 01:03:51,402] Trial 25 finished with value: 0.24259138679424733 and parameters: {'alpha': 1.7172508461483804e-05}. Best is trial 11 with value: 0.25105810324678146.\n",
      "[I 2023-07-09 01:04:13,244] Trial 26 finished with value: 0.2426002172787966 and parameters: {'alpha': 1.0162943844653687e-05}. Best is trial 11 with value: 0.25105810324678146.\n",
      "[I 2023-07-09 01:04:31,781] Trial 27 finished with value: 0.2433866878891449 and parameters: {'alpha': 2.7584777668678435e-05}. Best is trial 11 with value: 0.25105810324678146.\n",
      "[I 2023-07-09 01:04:52,939] Trial 28 finished with value: 0.24544959646879336 and parameters: {'alpha': 1.6931405716601866e-05}. Best is trial 11 with value: 0.25105810324678146.\n",
      "[I 2023-07-09 01:05:13,682] Trial 29 finished with value: 0.24187244152424828 and parameters: {'alpha': 2.324041277643156e-05}. Best is trial 11 with value: 0.25105810324678146.\n",
      "[I 2023-07-09 01:05:39,051] Trial 30 finished with value: 0.2450022936476338 and parameters: {'alpha': 1.4676495879883335e-05}. Best is trial 11 with value: 0.25105810324678146.\n",
      "[I 2023-07-09 01:06:03,293] Trial 31 finished with value: 0.25697112279764384 and parameters: {'alpha': 3.1177763903493924e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:06:29,718] Trial 32 finished with value: 0.24633170466301224 and parameters: {'alpha': 2.2834597854491437e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:06:45,270] Trial 33 finished with value: 0.2455524869018643 and parameters: {'alpha': 2.757240501115031e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:07:00,921] Trial 34 finished with value: 0.2421434527488106 and parameters: {'alpha': 5.576080518320541e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:07:18,017] Trial 35 finished with value: 0.247501039793804 and parameters: {'alpha': 1.7713738856108824e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:07:35,653] Trial 36 finished with value: 0.244417561517502 and parameters: {'alpha': 1.3388153832028075e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:07:52,626] Trial 37 finished with value: 0.23205353513251317 and parameters: {'alpha': 2.082920904859049e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:08:08,344] Trial 38 finished with value: 0.24687236249048944 and parameters: {'alpha': 3.023765916014283e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:08:27,823] Trial 39 finished with value: 0.24155884399465105 and parameters: {'alpha': 1.3190393187463308e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:08:46,288] Trial 40 finished with value: 0.23849891938108825 and parameters: {'alpha': 4.894147216220492e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:09:02,005] Trial 41 finished with value: 0.24546572730321106 and parameters: {'alpha': 3.171697200076055e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:09:20,267] Trial 42 finished with value: 0.2447655602405328 and parameters: {'alpha': 6.878762862872559e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:09:38,040] Trial 43 finished with value: 0.2501305045684147 and parameters: {'alpha': 4.181721905053192e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:09:57,561] Trial 44 finished with value: 0.24354319305864217 and parameters: {'alpha': 4.6385265960309633e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:10:14,684] Trial 45 finished with value: 0.24397943435965855 and parameters: {'alpha': 2.2855110726303127e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:10:31,104] Trial 46 finished with value: 0.25461552307983076 and parameters: {'alpha': 3.356667593144216e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:10:47,006] Trial 47 finished with value: 0.2443203216780435 and parameters: {'alpha': 3.579868502422329e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:11:02,404] Trial 48 finished with value: 0.24573432399516 and parameters: {'alpha': 7.723845727000515e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:11:20,593] Trial 49 finished with value: 0.23677507950778226 and parameters: {'alpha': 1.219064100976599e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:11:39,600] Trial 50 finished with value: 0.24496283399572172 and parameters: {'alpha': 1.637196050454577e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:11:55,736] Trial 51 finished with value: 0.24692094755903118 and parameters: {'alpha': 4.073293622724835e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:12:11,859] Trial 52 finished with value: 0.2399897690866292 and parameters: {'alpha': 3.1552469239737614e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:12:34,538] Trial 53 finished with value: 0.2546941975882043 and parameters: {'alpha': 1.9970782025482694e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:12:51,184] Trial 54 finished with value: 0.25546368239978456 and parameters: {'alpha': 1.9891791303082324e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:13:07,778] Trial 55 finished with value: 0.24576171485209422 and parameters: {'alpha': 2.1109020392848018e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:13:25,414] Trial 56 finished with value: 0.2463082421669587 and parameters: {'alpha': 1.5616710644289634e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:13:42,786] Trial 57 finished with value: 0.23994926295442412 and parameters: {'alpha': 1.9289105682524324e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:13:58,026] Trial 58 finished with value: 0.2491506137029546 and parameters: {'alpha': 4.091244895871734e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:14:17,395] Trial 59 finished with value: 0.24606740089502344 and parameters: {'alpha': 2.569055741127719e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:14:33,940] Trial 60 finished with value: 0.24294924014902183 and parameters: {'alpha': 3.4045998922870064e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:14:52,073] Trial 61 finished with value: 0.2540230274640537 and parameters: {'alpha': 1.1472191777568072e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:15:09,393] Trial 62 finished with value: 0.2519264429181633 and parameters: {'alpha': 1.4013936887866645e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:15:27,000] Trial 63 finished with value: 0.24520275395691066 and parameters: {'alpha': 1.2726106764620734e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:15:44,577] Trial 64 finished with value: 0.24122532838670763 and parameters: {'alpha': 1.4290811462829023e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:16:01,961] Trial 65 finished with value: 0.24159267670208281 and parameters: {'alpha': 1.1809806572612492e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:16:18,697] Trial 66 finished with value: 0.2405346178890991 and parameters: {'alpha': 1.8397512153372138e-05}. Best is trial 31 with value: 0.25697112279764384.\n",
      "[I 2023-07-09 01:16:34,366] Trial 67 finished with value: 0.25925505583195985 and parameters: {'alpha': 1.035304273749283e-05}. Best is trial 67 with value: 0.25925505583195985.\n",
      "[I 2023-07-09 01:16:52,773] Trial 68 finished with value: 0.24940281691691948 and parameters: {'alpha': 1.0065184044307087e-05}. Best is trial 67 with value: 0.25925505583195985.\n",
      "[I 2023-07-09 01:17:10,722] Trial 69 finished with value: 0.24237531927570863 and parameters: {'alpha': 1.4473444221079422e-05}. Best is trial 67 with value: 0.25925505583195985.\n",
      "[I 2023-07-09 01:17:28,044] Trial 70 finished with value: 0.24342371903637164 and parameters: {'alpha': 1.6117161655287977e-05}. Best is trial 67 with value: 0.25925505583195985.\n",
      "[I 2023-07-09 01:17:45,690] Trial 71 finished with value: 0.23803690099151614 and parameters: {'alpha': 1.171609851828409e-05}. Best is trial 67 with value: 0.25925505583195985.\n",
      "[I 2023-07-09 01:18:03,300] Trial 72 finished with value: 0.2511702100118665 and parameters: {'alpha': 1.1138373023148315e-05}. Best is trial 67 with value: 0.25925505583195985.\n",
      "[I 2023-07-09 01:18:23,140] Trial 73 finished with value: 0.23863154137256862 and parameters: {'alpha': 1.1503656584656444e-05}. Best is trial 67 with value: 0.25925505583195985.\n",
      "[I 2023-07-09 01:18:40,043] Trial 74 finished with value: 0.24271256513312225 and parameters: {'alpha': 1.8721594388069155e-05}. Best is trial 67 with value: 0.25925505583195985.\n",
      "[I 2023-07-09 01:18:57,379] Trial 75 finished with value: 0.24047635402660372 and parameters: {'alpha': 1.5067394648082329e-05}. Best is trial 67 with value: 0.25925505583195985.\n",
      "[I 2023-07-09 01:19:14,680] Trial 76 finished with value: 0.2439994417835265 and parameters: {'alpha': 2.4905894586759528e-05}. Best is trial 67 with value: 0.25925505583195985.\n",
      "[I 2023-07-09 01:19:32,994] Trial 77 finished with value: 0.2402502123998729 and parameters: {'alpha': 1.3265677149012134e-05}. Best is trial 67 with value: 0.25925505583195985.\n",
      "[I 2023-07-09 01:19:51,053] Trial 78 finished with value: 0.2470459310022565 and parameters: {'alpha': 2.0807887194844106e-05}. Best is trial 67 with value: 0.25925505583195985.\n",
      "[I 2023-07-09 01:20:10,714] Trial 79 finished with value: 0.2413289587799201 and parameters: {'alpha': 1.0381226716524948e-05}. Best is trial 67 with value: 0.25925505583195985.\n",
      "[I 2023-07-09 01:20:27,882] Trial 80 finished with value: 0.2446353460624582 and parameters: {'alpha': 1.6082525200268827e-05}. Best is trial 67 with value: 0.25925505583195985.\n",
      "[I 2023-07-09 01:20:45,232] Trial 81 finished with value: 0.24403528982652326 and parameters: {'alpha': 1.161016460745745e-05}. Best is trial 67 with value: 0.25925505583195985.\n",
      "[I 2023-07-09 01:21:02,936] Trial 82 finished with value: 0.24980864719339646 and parameters: {'alpha': 1.3126582850582342e-05}. Best is trial 67 with value: 0.25925505583195985.\n",
      "[I 2023-07-09 01:21:22,518] Trial 83 finished with value: 0.2634924765255851 and parameters: {'alpha': 1.0115481228917037e-05}. Best is trial 83 with value: 0.2634924765255851.\n",
      "[I 2023-07-09 01:21:39,279] Trial 84 finished with value: 0.23536466277118895 and parameters: {'alpha': 1.7367585427129993e-05}. Best is trial 83 with value: 0.2634924765255851.\n",
      "[I 2023-07-09 01:21:57,779] Trial 85 finished with value: 0.2455894389817661 and parameters: {'alpha': 1.0898426989991431e-05}. Best is trial 83 with value: 0.2634924765255851.\n",
      "[I 2023-07-09 01:22:15,145] Trial 86 finished with value: 0.24563856435150339 and parameters: {'alpha': 1.430929993924815e-05}. Best is trial 83 with value: 0.2634924765255851.\n",
      "[I 2023-07-09 01:22:33,414] Trial 87 finished with value: 0.2562542605286275 and parameters: {'alpha': 1.0135201531859598e-05}. Best is trial 83 with value: 0.2634924765255851.\n",
      "[I 2023-07-09 01:22:51,743] Trial 88 finished with value: 0.25154543425399317 and parameters: {'alpha': 1.0054853249550268e-05}. Best is trial 83 with value: 0.2634924765255851.\n",
      "[I 2023-07-09 01:23:09,002] Trial 89 finished with value: 0.2473622651794219 and parameters: {'alpha': 1.2624056381258557e-05}. Best is trial 83 with value: 0.2634924765255851.\n",
      "[I 2023-07-09 01:23:26,205] Trial 90 finished with value: 0.24003329843197935 and parameters: {'alpha': 2.2933273827705745e-05}. Best is trial 83 with value: 0.2634924765255851.\n",
      "[I 2023-07-09 01:23:44,928] Trial 91 finished with value: 0.2366598230122829 and parameters: {'alpha': 1.0614827199967526e-05}. Best is trial 83 with value: 0.2634924765255851.\n",
      "[I 2023-07-09 01:24:03,090] Trial 92 finished with value: 0.2536257782133406 and parameters: {'alpha': 1.422568668724317e-05}. Best is trial 83 with value: 0.2634924765255851.\n",
      "[I 2023-07-09 01:24:20,096] Trial 93 finished with value: 0.2428427107576168 and parameters: {'alpha': 1.7445098122855778e-05}. Best is trial 83 with value: 0.2634924765255851.\n",
      "[I 2023-07-09 01:24:37,892] Trial 94 finished with value: 0.23513077252329334 and parameters: {'alpha': 1.4092347030527541e-05}. Best is trial 83 with value: 0.2634924765255851.\n",
      "[I 2023-07-09 01:24:54,842] Trial 95 finished with value: 0.24982428901298626 and parameters: {'alpha': 1.9711795181231464e-05}. Best is trial 83 with value: 0.2634924765255851.\n",
      "[I 2023-07-09 01:25:13,125] Trial 96 finished with value: 0.23769493954353305 and parameters: {'alpha': 1.2794372243559077e-05}. Best is trial 83 with value: 0.2634924765255851.\n",
      "[I 2023-07-09 01:25:33,211] Trial 97 finished with value: 0.2415826732803809 and parameters: {'alpha': 1.4852689156586526e-05}. Best is trial 83 with value: 0.2634924765255851.\n",
      "[I 2023-07-09 01:25:53,770] Trial 98 finished with value: 0.24035391565620084 and parameters: {'alpha': 1.6487288314322608e-05}. Best is trial 83 with value: 0.2634924765255851.\n",
      "[I 2023-07-09 01:26:13,475] Trial 99 finished with value: 0.2515454837194404 and parameters: {'alpha': 1.2288158381704998e-05}. Best is trial 83 with value: 0.2634924765255851.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 0.2634924765255851 {'alpha': 1.0115481228917037e-05}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from uuid import uuid4\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def process(split='train'):    \n",
    "   \n",
    "    utterance = []\n",
    "    ids = []\n",
    "    label = []\n",
    "    act = []\n",
    "    \n",
    "    # Apply the function to all examples in the dataset\n",
    "    dataset = load_dataset('daily_dialog', split=split)\n",
    "    \n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        example = dataset[i]\n",
    "        did = uuid4()\n",
    "        for j in range(len(example['dialog'])):\n",
    "            text = example['dialog'][j]\n",
    "            # add previous sentnce xontext\n",
    "            if j > 1:\n",
    "                text = 'emotion' + ' '+ str(example['emotion'][j - 1]) + ' ' + example['dialog'][j - 1] + ' ' + text\n",
    "            utterance.append(example['dialog'][j])\n",
    "            act.append(example['act'][j])\n",
    "            label.append(example['emotion'][j])\n",
    "            ids.append(did)\n",
    "\n",
    "    data = {\n",
    "        'text': utterance,\n",
    "        'label': label,\n",
    "        'attr': act,\n",
    "        'id': ids\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data=data)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train = process(split='train')\n",
    "print('n train', len(df_train))\n",
    "df_valid = process(split='validation')\n",
    "df_test = process(split='test')\n",
    "\n",
    "# improves macro f1\n",
    "\n",
    "\n",
    "counts = Counter(df_train.label)\n",
    "print('train label dist.', counts)\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "#df_train = df_train.sample(10000).reset_index(drop=True)\n",
    "#df_valid = df_valid.sample(100)\n",
    "#df_test = df_test.sample(100)\n",
    "\n",
    "train_sentences = df_train.text.to_numpy()\n",
    "valid_sentences = df_valid.text.to_numpy()\n",
    "test_sentences = df_test.text.to_numpy()\n",
    "\n",
    "print('start encode train')\n",
    "x_train = model.encode(train_sentences, show_progress_bar=True, convert_to_numpy=True)\n",
    "\n",
    "# over sample the embeddings\n",
    "rus = RandomOverSampler(random_state=42)\n",
    "df_train['index_0'] = df_train.index\n",
    "df_train, _ = rus.fit_resample(df_train, df_train.label)\n",
    "x_train = np.array(x_train)\n",
    "x_train = x_train[df_train.index_0]\n",
    "print(x_train.shape)\n",
    "\n",
    "counts = Counter(df_train.label)\n",
    "print('train label dist.', counts)\n",
    "\n",
    "print('end encode train')\n",
    "x_valid = model.encode(valid_sentences, show_progress_bar=True, convert_to_numpy=True)\n",
    "x_test = model.encode(test_sentences, show_progress_bar=True, convert_to_numpy=True)\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    # hyper params\n",
    "    alpha = trial.suggest_float('alpha', 1e-5, 1e-3, log=True)\n",
    "\n",
    "    clf = SGDClassifier(loss='log_loss', penalty='l2', alpha=alpha, n_jobs=-1)\n",
    "    #clf = RandomForestClassifier(n_estimators=200, max_depth=200)\n",
    "\n",
    "    clf.fit(x_train, df_train.label)\n",
    "\n",
    "    y_pred = clf.predict(x_valid)\n",
    "    y_true = df_valid.label\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "study.best_params  # E.g. {'x': 2.002108042}\n",
    "print('f1', study.best_value, study.best_params) # alpha 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25843587584681377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.51      0.66      6321\n",
      "           1       0.11      0.51      0.18       118\n",
      "           2       0.05      0.38      0.08        47\n",
      "           3       0.03      0.47      0.05        17\n",
      "           4       0.39      0.65      0.49      1019\n",
      "           5       0.08      0.65      0.15       102\n",
      "           6       0.12      0.63      0.20       116\n",
      "\n",
      "    accuracy                           0.53      7740\n",
      "   macro avg       0.25      0.54      0.26      7740\n",
      "weighted avg       0.83      0.53      0.61      7740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='log_loss', penalty='l2', alpha=1.0115481228917037e-05, n_jobs=-1)\n",
    "\n",
    "clf.fit(x_train, df_train.label)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "y_true = df_test.label\n",
    "report = classification_report(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "print(f1)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
